{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahriariit/phishingTL/blob/main/New_Code_TL_using_5000_sample_with_8_feature_sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdKyx-OVj3hW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
        "    ExtraTreesClassifier, BaggingClassifier, StackingClassifier, VotingClassifier\n",
        ")\n",
        "from sklearn.linear_model import (\n",
        "    LogisticRegression, RidgeClassifier, Perceptron, SGDClassifier, PassiveAggressiveClassifier\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "\n",
        "# External libraries\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "#from catboost import CatBoostClassifier\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE, SequentialFeatureSelector\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, auc\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix, precision_score, recall_score, f1_score,\n",
        "    classification_report, roc_curve, roc_auc_score, log_loss, jaccard_score,\n",
        "    hamming_loss, matthews_corrcoef, cohen_kappa_score, hinge_loss\n",
        ")\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_gH-H69kpvA"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('https://media.githubusercontent.com/media/shahriariit/opendataset/master/PhiUSIIL_phishing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPi86Wtf_lOh"
      },
      "outputs": [],
      "source": [
        "def data_split_simulation(df, num_unlabeled, random_state=42):\n",
        "     df = df.copy()\n",
        "\n",
        "     np.random.seed(random_state)\n",
        "     unlabeled_indices = np.random.choice(\n",
        "        df.index,\n",
        "        size=num_unlabeled,\n",
        "        replace=False,\n",
        "        )\n",
        "\n",
        "     # Store true labels for unlabeled data (for final evaluation)\n",
        "     y_unlabeled_true = df.loc[unlabeled_indices, 'label'].copy()\n",
        "\n",
        "     # Mask labels for unlabeled samples\n",
        "     df.loc[unlabeled_indices, 'label'] = -1\n",
        "\n",
        "     # Split using boolean masks (correct transductive approach)\n",
        "     mask_labeled = df['label'] != -1\n",
        "     X_labeled = df[mask_labeled].drop('label', axis=1)\n",
        "     y_labeled = df[mask_labeled]['label']\n",
        "     X_unlabeled = df[~mask_labeled].drop('label', axis=1)\n",
        "\n",
        "     return X_labeled, X_unlabeled, y_labeled, y_unlabeled_true\n",
        "\n",
        "def subdataset_by_correlation_analysis(data, threshold=0.9):\n",
        "\n",
        "    if 'label' not in data.columns:\n",
        "        raise ValueError(\"Dataset must contain a 'label' column as the target variable.\")\n",
        "\n",
        "    M = data.drop(columns=['label'])\n",
        "    n = data['label']\n",
        "    correlation_matrix = M.corr()\n",
        "    high_corr_var = np.where((correlation_matrix >= threshold) | (correlation_matrix <= -threshold))\n",
        "    high_corr_pairs = [(correlation_matrix.columns[x], correlation_matrix.columns[y])\n",
        "                       for x, y in zip(*high_corr_var) if x != y and x < y]\n",
        "\n",
        "    columns_to_drop = set()\n",
        "    for feature1, feature2 in high_corr_pairs:\n",
        "        columns_to_drop.add(feature1)\n",
        "        columns_to_drop.add(feature2)\n",
        "\n",
        "    reduced_data = M.drop(columns=columns_to_drop, axis=1)\n",
        "    reduced_data['label'] = n.values\n",
        "    return reduced_data\n",
        "\n",
        "def subdataset_by_kbest(data, k=10):\n",
        "    if 'label' not in data.columns:\n",
        "        raise ValueError(\"Dataset must contain a 'label' column as the target variable.\")\n",
        "\n",
        "    X = data.drop(columns=['label'])  # Features\n",
        "    y = data['label']  # Target variable\n",
        "    selector = SelectKBest(score_func=f_classif, k=k)\n",
        "    selector.fit(X, y)\n",
        "    selected_features = X.columns[selector.get_support()]\n",
        "    reduced_data = X[selected_features].copy()\n",
        "    reduced_data['label'] = y.values\n",
        "\n",
        "    return reduced_data\n",
        "\n",
        "def subdataset_by_rfe(data):\n",
        "    M = data.drop('label', axis=1)\n",
        "    n = data['label']\n",
        "    rf = RandomForestClassifier(random_state=42) # Aligned with the function definition\n",
        "    num_features = 15\n",
        "    rfe = RFE(estimator=rf, n_features_to_select=num_features, step=5)\n",
        "    rfe.fit(M, n)\n",
        "\n",
        "    selected_features = M.columns[rfe.support_]\n",
        "    new_data = M[selected_features].copy()\n",
        "    new_data['label'] = data['label']\n",
        "\n",
        "    return new_data\n",
        "\n",
        "def subdataset_by_mi(data, k=15):\n",
        "    top_features = top_features_from_mi(data)\n",
        "    top_feature_names = top_features['feature_name'].head(k).tolist()\n",
        "    top_feature_names.append('label')\n",
        "    selected_data = data[top_feature_names]\n",
        "    return selected_data\n",
        "\n",
        "\n",
        "def top_features_from_mi(data):\n",
        "\n",
        "    FIT_FEATURES = SelectKBest(score_func=mutual_info_classif, k='all')\n",
        "    X = data.drop('label', axis=1)\n",
        "    y = data['label']\n",
        "\n",
        "    FIT_FEATURES.fit(X, y)\n",
        "\n",
        "    score_col = pd.DataFrame(FIT_FEATURES.scores_, columns=['score_value'])\n",
        "    name_col = pd.DataFrame(X.columns, columns=['feature_name'])\n",
        "\n",
        "    top_features = pd.concat([name_col, score_col], axis=1)\n",
        "    top_features_sorted = top_features.sort_values('score_value', ascending=False)\n",
        "\n",
        "    return top_features_sorted\n",
        "\n",
        "def  top_features_from_sfs_LR(data):\n",
        "    log_reg = LogisticRegression(max_iter=1000)  # Default model\n",
        "    M = data.drop('label', axis=1)\n",
        "    n = data['label']\n",
        "\n",
        "    SFS = SequentialFeatureSelector(\n",
        "        log_reg,\n",
        "        n_features_to_select=15,  # Select 15 features\n",
        "        direction=\"forward\",  # Forward selection\n",
        "        cv=5  # 5-fold cross-validation\n",
        "    )\n",
        "    SFS.fit(M, n)\n",
        "    selected_features = np.array(M.columns)[SFS.get_support()]\n",
        "    top_feature= M[selected_features]\n",
        "    return selected_features, top_feature\n",
        "\n",
        "def subdataset_by_sfs_GNB(data):\n",
        "    MODEL = GaussianNB()\n",
        "    M = data.drop('label', axis=1)\n",
        "    n = data['label']\n",
        "\n",
        "    SFS = SequentialFeatureSelector(\n",
        "        MODEL,\n",
        "        n_features_to_select=15,\n",
        "        direction=\"forward\",\n",
        "        cv=3,\n",
        "        n_jobs=-1  # Parallel processing\n",
        "    )\n",
        "    SFS.fit(M, n) #Fixed the indentation error by removing the extra space\n",
        "    selected_features = np.array(M.columns)[SFS.get_support()]\n",
        "\n",
        "    selected_features_list = selected_features.tolist() + ['label']\n",
        "    return data[selected_features_list]\n",
        "\n",
        "def subdataset_by_rf(data):\n",
        "    MODEL = RandomForestClassifier()\n",
        "    M = data.drop('label', axis=1)\n",
        "    n = data['label']\n",
        "\n",
        "    MODEL.fit(M, n)\n",
        "    feature_importances = MODEL.feature_importances_\n",
        "\n",
        "    feature_scores = pd.DataFrame({'feature_name': M.columns, 'importance_score': feature_importances})\n",
        "    top_features = feature_scores.sort_values(by='importance_score', ascending=False).head(15)\n",
        "\n",
        "    return data[top_features['feature_name'].tolist() + ['label']]\n",
        "\n",
        "def subdataset_by_lr(data):\n",
        "    MODEL = LogisticRegression(max_iter=1000)  # Increase iterations for convergence\n",
        "    M = data.drop('label', axis=1)\n",
        "    n = data['label']\n",
        "\n",
        "    MODEL.fit(M, n)\n",
        "    feature_importances = np.abs(MODEL.coef_)[0]  # Get absolute coefficient values\n",
        "\n",
        "    feature_scores = pd.DataFrame({'feature_name': M.columns, 'importance_score': feature_importances})\n",
        "    top_features = feature_scores.sort_values(by='importance_score', ascending=False).head(15)\n",
        "\n",
        "    return data[top_features['feature_name'].tolist() + ['label']]\n",
        "\n",
        "\n",
        "def subdataset_by_pca(data):\n",
        "\n",
        "    M = data.drop('label', axis=1)\n",
        "    n = data['label']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    M_scaled = scaler.fit_transform(M)\n",
        "\n",
        "    # Apply PCA with automatic selection based on variance retention (85%)\n",
        "    pca = PCA(n_components=0.85)\n",
        "    M_pca = pca.fit_transform(M_scaled)\n",
        "\n",
        "    # Get the number of selected components\n",
        "    n_selected_components = pca.n_components_\n",
        "\n",
        "    # Convert PCA components into a DataFrame\n",
        "    pca_columns = [f'PC{i+1}' for i in range(n_selected_components)]\n",
        "    pca_df = pd.DataFrame(M_pca, columns=pca_columns)\n",
        "\n",
        "    # Add the target variable back\n",
        "    pca_df['label'] = n.reset_index(drop=True)\n",
        "\n",
        "    return pca_df\n",
        "\n",
        "def remove_outliers_iqr(df, k=1.5):\n",
        "    Q1 = df.quantile(0.25)\n",
        "    Q3 = df.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - k * IQR\n",
        "    upper_bound = Q3 + k * IQR\n",
        "    return df[~((df < lower_bound) | (df > upper_bound)).any(axis=1)]\n",
        "\n",
        "def z_score_transformation(df_train, df_test):\n",
        "    scaler = StandardScaler()\n",
        "    df_train_scaled = scaler.fit_transform(df_train)\n",
        "    df_test_scaled = scaler.transform(df_test)\n",
        "    return df_train_scaled, df_test_scaled\n",
        "\n",
        "def min_max_transformation(df_train, df_test):\n",
        "    scaler = MinMaxScaler()\n",
        "    df_train_scaled = scaler.fit_transform(df_train)\n",
        "    df_test_scaled = scaler.transform(df_test)\n",
        "    return df_train_scaled, df_test_scaled\n",
        "\n",
        "def log_transformation(df_train, df_test):\n",
        "    df_train_log = np.log1p(df_train)\n",
        "    df_test_log = np.log1p(df_test)\n",
        "    return df_train_log, df_test_log\n",
        "\n",
        "def gmean_score(y_true, y_pred, average='macro'):\n",
        "    \"\"\"\n",
        "    Calculate the Geometric Mean (G-mean) for multiclass classification.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels (array-like).\n",
        "        y_pred: Predicted labels (array-like).\n",
        "        average: Averaging method ('macro', 'weighted', or None).\n",
        "\n",
        "    Returns:\n",
        "        G-mean score (scalar or list if average=None).\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    n_classes = cm.shape[0]\n",
        "    total_samples = cm.sum()\n",
        "\n",
        "    gmeans = []\n",
        "    supports = []\n",
        "\n",
        "    for k in range(n_classes):\n",
        "        # True Positives (TP) and False Negatives (FN)\n",
        "        TP = cm[k, k]\n",
        "        FN = cm[k, :].sum() - TP\n",
        "\n",
        "        # False Positives (FP) and True Negatives (TN)\n",
        "        FP = cm[:, k].sum() - TP\n",
        "        TN = total_samples - TP - FN - FP\n",
        "\n",
        "        # Handle division by zero\n",
        "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0.0\n",
        "        specificity = TN / (TN + FP) if (TN + FP) != 0 else 0.0\n",
        "\n",
        "        # Compute G-mean for the class\n",
        "        gmean = np.sqrt(recall * specificity) if (recall * specificity) >= 0 else 0.0\n",
        "        gmeans.append(gmean)\n",
        "        supports.append(TP + FN)  # Support (number of true samples)\n",
        "\n",
        "    # Apply averaging\n",
        "    if average == 'macro':\n",
        "        return np.mean(gmeans)\n",
        "    elif average == 'weighted':\n",
        "        return np.average(gmeans, weights=supports)\n",
        "    elif average is None:\n",
        "        return gmeans\n",
        "    else:\n",
        "        raise ValueError(\"Invalid averaging method. Use 'macro', 'weighted', or None.\")\n",
        "\n",
        "def specificity_score(y_true, y_pred, average='macro'):\n",
        "    \"\"\"\n",
        "    Calculate specificity for multiclass classification.\n",
        "\n",
        "    Args:\n",
        "        y_true: Array of true labels.\n",
        "        y_pred: Array of predicted labels.\n",
        "        average: Averaging method ('macro', 'weighted', or None).\n",
        "\n",
        "    Returns:\n",
        "        Specificity score (scalar or list if average=None).\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    n_classes = cm.shape[0]\n",
        "    specificities = []\n",
        "\n",
        "    for k in range(n_classes):\n",
        "        # True negatives: Remove row k and column k, sum remaining elements\n",
        "        tn = np.delete(np.delete(cm, k, axis=0), k, axis=1).sum()\n",
        "        # False positives: Sum column k excluding the diagonal (true positives)\n",
        "        fp = cm[:, k].sum() - cm[k, k]\n",
        "\n",
        "        denominator = tn + fp\n",
        "        specificity = tn / denominator if denominator != 0 else 0.0\n",
        "        specificities.append(specificity)\n",
        "\n",
        "    if average == 'macro':\n",
        "        return np.mean(specificities)\n",
        "    elif average == 'weighted':\n",
        "        # Weight by the number of actual negatives per class\n",
        "        class_counts = cm.sum(axis=1)\n",
        "        total_samples = cm.sum()\n",
        "        weights = (total_samples - class_counts)  # Number of negatives per class\n",
        "        return np.average(specificities, weights=weights)\n",
        "    elif average is None:\n",
        "        return specificities\n",
        "    else:\n",
        "        raise ValueError(\"Invalid averaging method. Use 'macro', 'weighted', or None.\")\n",
        "\n",
        "def classification_metrics(X_labeled, X_unlabeled, y_labeled, y_unlabeled, output_file=\"classification_metrics.csv\"):\n",
        "    models = {\n",
        "       \"Linear SVC\": LinearSVC(random_state=42, max_iter=5000),\n",
        "       \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "       \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "       \"Logistic Regression\": LogisticRegression(),\n",
        "       \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "       \"Naive Bayes\": GaussianNB(),\n",
        "       \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "       \"Logistic Regression\": LogisticRegression(),\n",
        "       \"Ridge Classifier\": RidgeClassifier(),\n",
        "       \"Perceptron\": Perceptron(),\n",
        "       \"SGDClassifier\": SGDClassifier(),\n",
        "       \"PassiveAggressiveClassifier\": PassiveAggressiveClassifier(),\n",
        "       \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n",
        "       \"BaggingClassifier\": BaggingClassifier(),\n",
        "       \"LGBMClassifier\": LGBMClassifier(verbosity=-1)\n",
        "    }\n",
        "\n",
        "    # Open CSV file for writing\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header row\n",
        "        writer.writerow([\"Model\", \"Accuracy\", \"Cohen-Kappa\", \"Precision\", \"Recall\", \"Specificity\", \"F1-Score\", \"G-Mean\", \"AUROC\", \"Logloss\", \"Jaccard\", \"Hamming\",\"MCC\"])\n",
        "\n",
        "        for name, model in models.items():\n",
        "            #print(f\"Training {name}...\")\n",
        "            model.fit(X_labeled, y_labeled)\n",
        "            #y_pred = model.predict(X_unlabeled)\n",
        "\n",
        "            # Get the indices of the unlabeled samples in the original data\n",
        "            unlabeled_indices = y_unlabeled.index\n",
        "\n",
        "            # Select the corresponding features from X_unlabeled\n",
        "            X_unlabeled_subset = X_unlabeled.loc[unlabeled_indices]\n",
        "\n",
        "            y_pred = cross_val_predict(model, X_unlabeled_subset, y_unlabeled, cv=5)\n",
        "\n",
        "            # Check if the model has predict_proba and if it returns probabilities for all classes\n",
        "            try:  # Try to get probabilities, handle exceptions if not available\n",
        "                y_proba = model.predict_proba(X_unlabeled)\n",
        "                # Check if probabilities sum to 1 for each sample\n",
        "                if np.allclose(1, y_proba.sum(axis=1)):\n",
        "                    y_proba = y_proba[:, 1]  # Extract probabilities for class 1\n",
        "                    if y_proba.ndim == 1:\n",
        "                        y_proba = y_proba.reshape(-1, 1)\n",
        "                else:\n",
        "                    y_proba = None  # Set to None if probabilities are not valid\n",
        "            except (AttributeError, NotImplementedError):  # Catch exceptions\n",
        "                 y_proba = None   # Set to None if probabilities are not available\n",
        "\n",
        "            accuracy = accuracy_score(y_unlabeled, y_pred)\n",
        "            cohen_kappa = cohen_kappa_score(y_unlabeled, y_pred)\n",
        "            precision = precision_score(y_unlabeled, y_pred, average='weighted')\n",
        "            recall = recall_score(y_unlabeled, y_pred, average='weighted')\n",
        "            specificity = specificity_score(y_unlabeled, y_pred, average='weighted')\n",
        "            f_measure = f1_score(y_unlabeled, y_pred, average='weighted')\n",
        "            gmean = gmean_score(y_unlabeled, y_pred,  average='weighted')\n",
        "            classification_rep = classification_report(y_unlabeled, y_pred)\n",
        "\n",
        "            if y_proba is not None:\n",
        "                roc_auc = roc_auc_score(y_unlabeled, y_proba, multi_class='ovr', average='macro')\n",
        "                logloss = log_loss(y_unlabeled, y_proba)\n",
        "            else:\n",
        "                roc_auc = np.nan  # or some other indicator for missing value\n",
        "                logloss = np.nan\n",
        "\n",
        "            jaccard = jaccard_score(y_unlabeled, y_pred, average='weighted')\n",
        "            hamming = hamming_loss(y_unlabeled, y_pred)\n",
        "            mcc = matthews_corrcoef(y_unlabeled, y_pred)\n",
        "\n",
        "            writer.writerow([name, accuracy, cohen_kappa, precision, recall, specificity, f_measure, gmean, roc_auc, logloss, jaccard, hamming, mcc])\n",
        "\n",
        "            #print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "            #print(f\"Log Loss: {logloss:.4f}\")\n",
        "            #print(f\"Jaccard Score: {jaccard:.4f}\")\n",
        "            #print(f\"Hamming Score: {hamming:.4f}\")\n",
        "            #print(f\"MCC Score: {mcc:.4f}\")\n",
        "\n",
        "            #print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "    print(f\"Classification metrics saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu4Jx_KkFpRP"
      },
      "outputs": [],
      "source": [
        "data_fs_1 = subdataset_by_correlation_analysis(data,0.8)\n",
        "data_fs_2 = subdataset_by_kbest(data)\n",
        "data_fs_3 = subdataset_by_rfe(data)\n",
        "data_fs_4 = subdataset_by_mi(data)\n",
        "data_fs_5 = subdataset_by_rf(data)\n",
        "data_fs_6 = subdataset_by_lr(data)\n",
        "data_fs_7 = subdataset_by_sfs_GNB(data)\n",
        "data_fs_8 = subdataset_by_pca(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ3pmrxJIE2V",
        "outputId": "12b33455-8ac0-4718-d5d1-a04bd57a51c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset1 shape: (235795, 43)\n",
            "Dataset1 shape after removing outliers using IQR method: (26872, 43)\n",
            "\n",
            "Dataset2 shape: (235795, 11)\n",
            "Dataset2 shape after removing outliers using IQR method: (182259, 11)\n",
            "\n",
            "Dataset3 shape: (235795, 16)\n",
            "Dataset3 shape after removing outliers using IQR method: (89135, 16)\n",
            "\n",
            "Dataset4 shape: (235795, 16)\n",
            "Dataset4 shape after removing outliers using IQR method: (114027, 16)\n",
            "\n",
            "Dataset5 shape: (235795, 16)\n",
            "Dataset5 shape after removing outliers using IQR method: (90421, 16)\n",
            "\n",
            "Dataset6 shape: (235795, 16)\n",
            "Dataset6 shape after removing outliers using IQR method: (110147, 16)\n",
            "\n",
            "Dataset7 shape: (235795, 16)\n",
            "Dataset7 shape after removing outliers using IQR method: (164007, 16)\n",
            "\n",
            "Dataset8 shape: (235795, 27)\n",
            "Dataset8 shape after removing outliers using IQR method: (135302, 27)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 9):\n",
        "    original_data = globals()[f\"data_fs_{i}\"]\n",
        "    cleaned_data = remove_outliers_iqr(original_data)\n",
        "\n",
        "    globals()[f\"data_fs_{i}_no_outliers\"] = cleaned_data\n",
        "\n",
        "    print(f\"Dataset{i} shape:\", original_data.shape)\n",
        "    print(f\"Dataset{i} shape after removing outliers using IQR method:\", cleaned_data.shape)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = data_split_simulation(data,5000)\n",
        "classification_metrics(X_train, X_test, y_train, y_test,f\"classification_metrics_tl.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSZZSXCC-47Z",
        "outputId": "4566e91e-cccb-4590-efb4-d29fc2dcc83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx--L7Z8Kf8x"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 9):\n",
        "    (globals()[f\"X_train_tl_fs_{i}\"],\n",
        "     globals()[f\"X_test_tl_fs_{i}\"],\n",
        "     globals()[f\"y_train_tl_fs_{i}\"],\n",
        "     globals()[f\"y_test_tl_fs_{i}\"]) = data_split_simulation(globals()[f\"data_fs_{i}\"], 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rusSiXuUL3WL",
        "outputId": "678fe639-01e9-4f16-ea1a-0c8fe0c029a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs1.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs2.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs3.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs4.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs5.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs6.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs7.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs8.csv\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 9):\n",
        "    classification_metrics(\n",
        "        globals()[f\"X_train_tl_fs_{i}\"],\n",
        "        globals()[f\"X_test_tl_fs_{i}\"],\n",
        "        globals()[f\"y_train_tl_fs_{i}\"],\n",
        "        globals()[f\"y_test_tl_fs_{i}\"],\n",
        "        f\"classification_metrics_tl_fs{i}.csv\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 9):\n",
        "    (globals()[f\"X_train_tl_fs_no_{i}\"],\n",
        "     globals()[f\"X_test_tl_fs_no_{i}\"],\n",
        "     globals()[f\"y_train_tl_fs_no_{i}\"],\n",
        "     globals()[f\"y_test_tl_fs_no_{i}\"]) = data_split_simulation(globals()[f\"data_fs_{i}_no_outliers\"], 5000)"
      ],
      "metadata": {
        "id": "tcCQXgRu7JEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 9):\n",
        "    classification_metrics(\n",
        "        globals()[f\"X_train_tl_fs_no_{i}\"],\n",
        "        globals()[f\"X_test_tl_fs_no_{i}\"],\n",
        "        globals()[f\"y_train_tl_fs_no_{i}\"],\n",
        "        globals()[f\"y_test_tl_fs_no_{i}\"],\n",
        "        f\"classification_metrics_tl_fs{i}_no_outliers.csv\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKr4zff-72Pr",
        "outputId": "2556d1de-9563-4517-ab02-9a0277009e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs1_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs2_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs3_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs4_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs5_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs6_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs7_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_fs8_no_outliers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tl_scaled, X_test_tl_scaled = z_score_transformation(X_train, X_test)\n",
        "X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test,\"classification_metrics_tl_scaled.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3poeTWNA3Aj",
        "outputId": "345ef054-a5ec-41ac-e343-2650de47756c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_scaled.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tl_scaled, X_test_tl_scaled = min_max_transformation(X_train, X_test)\n",
        "X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test,\"classification_metrics_tl_mxscaled.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBtRNS2NFcv7",
        "outputId": "e89007bd-85e1-4d8d-f199-134cb9ba151e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_mxscaled.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tl_scaled, X_test_tl_scaled = log_transformation(X_train, X_test)\n",
        "X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test,\"classification_metrics_tl_logscaled.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22qdIzkGvsu",
        "outputId": "1be83797-7c17-4756-d26c-366e19764d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_tl_logscaled.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 9):\n",
        "    X_train = globals()[f\"X_train_tl_fs_{i}\"]\n",
        "    X_test = globals()[f\"X_test_tl_fs_{i}\"]\n",
        "    y_train = globals()[f\"y_train_tl_fs_{i}\"]\n",
        "    y_test = globals()[f\"y_test_tl_fs_{i}\"]\n",
        "\n",
        "    # Apply z-score scaling\n",
        "    X_train_tl_scaled, X_test_tl_scaled = z_score_transformation(X_train, X_test)\n",
        "    X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "    X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    # Store scaled data back to variables (optional if not needed later)\n",
        "    globals()[f\"X_train_scaled_tl_fs_{i}\"] = X_train_tl_scaled\n",
        "    globals()[f\"X_test_scaled_tl_fs_{i}\"] = X_test_tl_scaled\n",
        "\n",
        "    # Generate metrics filename\n",
        "    metrics_file = f\"classification_metrics_scaled_tl_fs{i}.csv\"\n",
        "\n",
        "    # Calculate and save metrics\n",
        "    classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test, metrics_file)"
      ],
      "metadata": {
        "id": "VxdoNArL5RDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 9):\n",
        "    X_train = globals()[f\"X_train_tl_fs_no_{i}\"]\n",
        "    X_test = globals()[f\"X_test_tl_fs_no_{i}\"]\n",
        "    y_train = globals()[f\"y_train_tl_fs_no_{i}\"]\n",
        "    y_test = globals()[f\"y_test_tl_fs_no_{i}\"]\n",
        "\n",
        "    # Apply z-score scaling\n",
        "    X_train_tl_scaled, X_test_tl_scaled = z_score_transformation(X_train, X_test)\n",
        "    X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "    X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    # Store scaled data back to variables (optional if not needed later)\n",
        "    globals()[f\"X_train_scaled_tl_fs_no_{i}\"] = X_train_tl_scaled\n",
        "    globals()[f\"X_test_scaled_tl_fs_no_{i}\"] = X_test_tl_scaled\n",
        "\n",
        "    # Generate metrics filename\n",
        "    metrics_file = f\"classification_metrics_scaled_tl_fs{i}_no_outliers.csv\"\n",
        "\n",
        "    # Calculate and save metrics\n",
        "    classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test, metrics_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqy1ereVLk0o",
        "outputId": "00685104-0d6d-4194-ef69-1d83f220fffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs1_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs2_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs3_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs4_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs5_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs6_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs7_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_scaled_tl_fs8_no_outliers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 9):\n",
        "    X_train = globals()[f\"X_train_tl_fs_{i}\"]\n",
        "    X_test = globals()[f\"X_test_tl_fs_{i}\"]\n",
        "    y_train = globals()[f\"y_train_tl_fs_{i}\"]\n",
        "    y_test = globals()[f\"y_test_tl_fs_{i}\"]\n",
        "\n",
        "    # Apply min-max scaling\n",
        "    X_train_tl_scaled, X_test_tl_scaled = min_max_transformation(X_train, X_test)\n",
        "    X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "    X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    # Store scaled data back to variables (optional if not needed later)\n",
        "    globals()[f\"X_train_mxscaled_tl_fs_{i}\"] = X_train_tl_scaled\n",
        "    globals()[f\"X_test_mxscaled_tl_fs_{i}\"] = X_test_tl_scaled\n",
        "\n",
        "    # Generate metrics filename\n",
        "    metrics_file = f\"classification_metrics_mxscaled_tl_fs{i}.csv\"\n",
        "\n",
        "    # Calculate and save metrics\n",
        "    classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test, metrics_file)"
      ],
      "metadata": {
        "id": "RP4xgE7J5ofs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 9):\n",
        "    X_train = globals()[f\"X_train_tl_fs_no_{i}\"]\n",
        "    X_test = globals()[f\"X_test_tl_fs_no_{i}\"]\n",
        "    y_train = globals()[f\"y_train_tl_fs_no_{i}\"]\n",
        "    y_test = globals()[f\"y_test_tl_fs_no_{i}\"]\n",
        "\n",
        "    # Apply min-max scaling\n",
        "    X_train_tl_scaled, X_test_tl_scaled = min_max_transformation(X_train, X_test)\n",
        "    X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "    X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    # Store scaled data back to variables (optional if not needed later)\n",
        "    globals()[f\"X_train_mxscaled_tl_fs_no_{i}\"] = X_train_tl_scaled\n",
        "    globals()[f\"X_test_mxscaled_tl_fs_no_{i}\"] = X_test_tl_scaled\n",
        "\n",
        "    # Generate metrics filename\n",
        "    metrics_file = f\"classification_metrics_mxscaled_tl_fs{i}_no_outliers.csv\"\n",
        "\n",
        "    # Calculate and save metrics\n",
        "    classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test, metrics_file)"
      ],
      "metadata": {
        "id": "YOYZ_Jtynfl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f283aa0-42e4-4dbd-a8fb-0a97ddd89dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs1_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs2_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs3_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs4_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs5_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs6_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs7_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_mxscaled_tl_fs8_no_outliers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 8):\n",
        "    X_train = globals()[f\"X_train_tl_fs_{i}\"]\n",
        "    X_test = globals()[f\"X_test_tl_fs_{i}\"]\n",
        "    y_train = globals()[f\"y_train_tl_fs_{i}\"]\n",
        "    y_test = globals()[f\"y_test_tl_fs_{i}\"]\n",
        "\n",
        "    # Apply log scaling\n",
        "    X_train_tl_scaled, X_test_tl_scaled = log_transformation(X_train, X_test)\n",
        "    X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "    X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    # Store scaled data back to variables (optional if not needed later)\n",
        "    globals()[f\"X_train_logscaled_tl_fs_{i}\"] = X_train_tl_scaled\n",
        "    globals()[f\"X_test_logscaled_tl_fs_{i}\"] = X_test_tl_scaled\n",
        "\n",
        "    # Generate metrics filename\n",
        "    metrics_file = f\"classification_metrics_logscaled_tl_fs{i}.csv\"\n",
        "\n",
        "    # Calculate and save metrics\n",
        "    classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test, metrics_file)"
      ],
      "metadata": {
        "id": "s3fmkLoG5zjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 8):\n",
        "    X_train = globals()[f\"X_train_tl_fs_no_{i}\"]\n",
        "    X_test = globals()[f\"X_test_tl_fs_no_{i}\"]\n",
        "    y_train = globals()[f\"y_train_tl_fs_no_{i}\"]\n",
        "    y_test = globals()[f\"y_test_tl_fs_no_{i}\"]\n",
        "\n",
        "    # Apply log scaling\n",
        "    X_train_tl_scaled, X_test_tl_scaled = log_transformation(X_train, X_test)\n",
        "    X_train_tl_scaled = pd.DataFrame(X_train_tl_scaled, columns=X_train.columns, index=X_train.index)\n",
        "    X_test_tl_scaled = pd.DataFrame(X_test_tl_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    # Store scaled data back to variables (optional if not needed later)\n",
        "    globals()[f\"X_train_logscaled_tl_fs_no_{i}\"] = X_train_tl_scaled\n",
        "    globals()[f\"X_test_logscaled_tl_fs_no_{i}\"] = X_test_tl_scaled\n",
        "\n",
        "    # Generate metrics filename\n",
        "    metrics_file = f\"classification_metrics_logscaled_tl_fs{i}_no_outliers.csv\"\n",
        "\n",
        "    # Calculate and save metrics\n",
        "    classification_metrics(X_train_tl_scaled, X_test_tl_scaled, y_train, y_test, metrics_file)"
      ],
      "metadata": {
        "id": "dC1pNT_SoUZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe0119f-9863-49dd-9f5a-1a99b889b3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_logscaled_tl_fs1_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_logscaled_tl_fs2_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_logscaled_tl_fs3_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_logscaled_tl_fs4_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_logscaled_tl_fs5_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_logscaled_tl_fs6_no_outliers.csv\n",
            "Training Linear SVC...\n",
            "Training Random Forest...\n",
            "Training Gradient Boosting...\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training Naive Bayes...\n",
            "Training AdaBoost...\n",
            "Training Ridge Classifier...\n",
            "Training Perceptron...\n",
            "Training SGDClassifier...\n",
            "Training PassiveAggressiveClassifier...\n",
            "Training ExtraTreesClassifier...\n",
            "Training BaggingClassifier...\n",
            "Training LGBMClassifier...\n",
            "Classification metrics saved to classification_metrics_logscaled_tl_fs7_no_outliers.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4nA2Xy0nTPlMUz42uRiH7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}